{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Growth Rate Prediction\n",
    "> Predictions of COVID-19 Growth Rates Using Bayesian Modeling\n",
    "\n",
    "- comments: true\n",
    "- author: Thomas Wiecki\n",
    "- categories: [growth]\n",
    "- image: images/covid-bayesian.png\n",
    "- permalink: /growth-bayes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\u20285826\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import pymc3 as pm\n",
    "\n",
    "import requests\n",
    "import io\n",
    "\n",
    "sns.set_context('talk')\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u20285826\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "\n",
    "def load_timeseries(name, \n",
    "                    base_url='https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series'):\n",
    "    import requests\n",
    "    # Thanks to kasparthommen for the suggestion to directly download\n",
    "    url = f'{base_url}/time_series_19-covid-{name}.csv'\n",
    "    csv = requests.get(url).text\n",
    "    df = pd.read_csv(io.StringIO(csv), \n",
    "                     index_col=['Country/Region', 'Province/State', 'Lat', 'Long'])\n",
    "    df['type'] = name.lower()\n",
    "    df.columns.name = 'date'\n",
    "    \n",
    "    df = (df.set_index('type', append=True)\n",
    "            .reset_index(['Lat', 'Long'], drop=True)\n",
    "            .stack()\n",
    "            .reset_index()\n",
    "            .set_index('date')\n",
    "         )\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.columns = ['country', 'state', 'type', 'cases']\n",
    "    \n",
    "    # Move HK to country level\n",
    "    df.loc[df.state =='Hong Kong', 'country'] = 'Hong Kong'\n",
    "    df.loc[df.state =='Hong Kong', 'state'] = np.nan\n",
    "    \n",
    "    # Aggregate large countries split by states\n",
    "    df = pd.concat([df, \n",
    "                    (df.loc[~df.state.isna()]\n",
    "                     .groupby(['country', 'date', 'type'])\n",
    "                     .sum()\n",
    "                     .rename(index=lambda x: x+' (total)', level=0)\n",
    "                     .reset_index(level=['country', 'type']))\n",
    "                   ])\n",
    "    return df\n",
    "\n",
    "df_confirmed = load_timeseries('Confirmed')\n",
    "# Drop states for simplicity\n",
    "df_confirmed = df_confirmed.loc[df_confirmed.state.isnull()]\n",
    "# Estimated critical cases\n",
    "p_crit = .05\n",
    "df_confirmed = df_confirmed.assign(cases_crit=df_confirmed.cases*p_crit)\n",
    "\n",
    "# Compute days relative to when 100 confirmed cases was crossed\n",
    "df_confirmed.loc[:, 'days_since_100'] = np.nan\n",
    "for country in df_confirmed.country.unique():\n",
    "    df_confirmed.loc[(df_confirmed.country == country), 'days_since_100'] = \\\n",
    "        np.arange(-len(df_confirmed.loc[(df_confirmed.country == country) & (df_confirmed.cases < 100)]), \n",
    "                  len(df_confirmed.loc[(df_confirmed.country == country) & (df_confirmed.cases >= 100)]))\n",
    "    \n",
    "# Select countries for which we have at least some information\n",
    "countries = pd.Series(df_confirmed.loc[df_confirmed.days_since_100 >= 2].country.unique())\n",
    "# We only have data for China after they already had a significant number of cases.\n",
    "# They also are not well modeled by the exponential, so we drop them here for simplicity.\n",
    "countries = countries.loc[~countries.isin(['China (total)', 'Cruise Ship (total)'])]\n",
    "df_sign = df_confirmed.loc[lambda x: x.country.isin(countries) & (x.days_since_100 >= 0)]\n",
    "n_countries = len(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the countries included in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thailand\n",
      "Japan\n",
      "Singapore\n",
      "Malaysia\n",
      "Germany\n",
      "Finland\n",
      "Philippines\n",
      "India\n",
      "Italy\n",
      "Sweden\n",
      "Spain\n",
      "Belgium\n",
      "Egypt\n",
      "Iraq\n",
      "Bahrain\n",
      "Kuwait\n",
      "Switzerland\n",
      "Austria\n",
      "Israel\n",
      "Brazil\n",
      "Greece\n",
      "Norway\n",
      "Romania\n",
      "Estonia\n",
      "San Marino\n",
      "Iceland\n",
      "Ireland\n",
      "Qatar\n",
      "Indonesia\n",
      "Portugal\n",
      "Saudi Arabia\n",
      "Poland\n",
      "Slovenia\n",
      "Iran\n",
      "Korea, South\n",
      "Hong Kong\n",
      "Czechia\n",
      "Australia (total)\n",
      "Canada (total)\n",
      "Denmark (total)\n",
      "France (total)\n",
      "Netherlands (total)\n",
      "US (total)\n",
      "United Kingdom (total)\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "for c in countries:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Growth Rate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "with pm.Model() as model:\n",
    "    ############\n",
    "    # Intercept\n",
    "    # Group mean\n",
    "    a_grp = pm.Normal('a_grp', 100, 50)\n",
    "    # Group variance\n",
    "    a_grp_sigma = pm.HalfNormal('a_grp_sigma', 50)\n",
    "    # Individual intercepts\n",
    "    a_ind = pm.Normal('a_ind', \n",
    "                      mu=a_grp, sigma=a_grp_sigma, \n",
    "                      shape=n_countries)\n",
    "    ########\n",
    "    # Slope\n",
    "    # Group mean\n",
    "    b_grp = pm.Normal('b_grp', 1.33, .5)\n",
    "    # Group variance\n",
    "    b_grp_sigma = pm.HalfNormal('b_grp_sigma', .5)\n",
    "    # Individual slopes\n",
    "    b_ind = pm.Normal('b_ind', \n",
    "                      mu=b_grp, sigma=b_grp_sigma, \n",
    "                      shape=n_countries)\n",
    "    \n",
    "    # Error\n",
    "    sigma = pm.HalfNormal('sigma', 500., shape=n_countries)\n",
    "    \n",
    "    # Create likelihood for each country\n",
    "    for i, country in enumerate(countries):\n",
    "        df_country = df_sign.loc[lambda x: (x.country == country)]\n",
    "        \n",
    "        # By using pm.Data we can change these values after sampling.\n",
    "        # This allows us to extend x into the future so we can get\n",
    "        # forecasts by sampling from the posterior predictive\n",
    "        x = pm.Data(country + \"x_data\", \n",
    "                    df_country.days_since_100.values)\n",
    "        cases = pm.Data(country + \"y_data\", \n",
    "                        df_country.cases.astype('float64').values)\n",
    "        \n",
    "        # Likelihood\n",
    "        pm.NegativeBinomial(\n",
    "            country, \n",
    "            (a_ind[i] * b_ind[i] ** x), # Exponential regression\n",
    "            sigma[i], \n",
    "            observed=cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [sigma, b_ind, b_grp_sigma, b_grp, a_ind, a_grp_sigma, a_grp]\n",
      "Sampling chain 0, 0 divergences:   9%| | 176/2000 [1:28:34<21:46:41, 42.98s/it]C:\\Users\\u20285826\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "Sampling chain 0, 0 divergences:   9%| | 176/2000 [1:29:03<15:22:56, 30.36s/it]\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n",
      "  0%|                                                  | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-94265a250277>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Sample posterior predictive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mpost_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_posterior_predictive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pymc3\\sampling.py\u001b[0m in \u001b[0;36msample_posterior_predictive\u001b[1;34m(trace, samples, model, vars, var_names, size, keep_size, random_seed, progressbar)\u001b[0m\n\u001b[0;32m   1277\u001b[0m                 \u001b[0mparam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_straces\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchain_idx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnchain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1279\u001b[1;33m                 \u001b[0mparam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen_trace\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1281\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pymc3\\backends\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Passed variable or variable name.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pymc3\\backends\\base.py\u001b[0m in \u001b[0;36mpoint\u001b[1;34m(self, idx, chain)\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchain\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mchain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_straces\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchains\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pymc3\\backends\\ndarray.py\u001b[0m in \u001b[0;36mpoint\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         return {varname: values[idx]\n\u001b[1;32m--> 322\u001b[1;33m                 for varname, values in self.samples.items()}\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pymc3\\backends\\ndarray.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         return {varname: values[idx]\n\u001b[1;32m--> 322\u001b[1;33m                 for varname, values in self.samples.items()}\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "with model:\n",
    "    # Sample posterior\n",
    "    trace = pm.sample(tune=1500, chains=1, cores=1, target_accept=.9)\n",
    "    \n",
    "    # Update data so that we get predictions into the future\n",
    "    for country in countries:\n",
    "        df_country = df_sign.loc[lambda x: (x.country == country)]\n",
    "        x_data = np.arange(0, 30)\n",
    "        y_data = np.array([np.nan] * len(x_data))\n",
    "        pm.set_data({country + \"x_data\": x_data})\n",
    "        pm.set_data({country + \"y_data\": y_data})\n",
    "    \n",
    "    # Sample posterior predictive\n",
    "    post_pred = pm.sample_posterior_predictive(trace, samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "european_countries = ['Italy', 'Germany', 'France (total)', 'Spain', 'United Kingdom (total)', \n",
    "                      'Iran']\n",
    "large_engl_countries = ['US (total)', 'Canada (total)', 'Australia (total)']\n",
    "asian_countries = ['Singapore', 'Japan', 'Korea, South', 'Hong Kong']\n",
    "south_american_countries = ['Argentina', 'Brazil', 'Colombia', 'Chile']\n",
    "\n",
    "country_groups = [european_countries, large_engl_countries, asian_countries]\n",
    "line_styles = ['-', ':', '--', '-.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "fig, axs = plt.subplots(nrows=len(country_groups), figsize=(8, 16), sharex=True)\n",
    "\n",
    "for ax, country_group in zip(axs, country_groups):\n",
    "    for i, country in enumerate(countries):\n",
    "        if country in country_group:\n",
    "            sns.distplot((trace['b_ind'][:, i] * 100) - 100, ax=ax, label=country, hist=False)\n",
    "        \n",
    "    ax.axvline(33, ls='--', color='k', label='33% daily growth')\n",
    "    ax.legend()\n",
    "ax.set_xlabel('Daily growth in %')\n",
    "plt.suptitle('Posterior of daily growth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted Cases By Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#hide_input\n",
    "fig, axs = plt.subplots(nrows=n_countries // 3, ncols=3, figsize=(15, 30), sharex=True)\n",
    "\n",
    "for ax, country in zip(axs.flatten(), countries):\n",
    "    df_country = df_sign.loc[lambda x: x.country == country]\n",
    "    ax.plot(df_country.days_since_100, df_country.cases, color='r')\n",
    "    ax.plot(np.arange(0, post_pred[country].shape[1]), post_pred[country].T, alpha=.05, color='.5')\n",
    "    ax.plot(df_country.days_since_100, df_country.cases, color='r')\n",
    "    #ax.set_yscale('log')\n",
    "    #ax.get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "    ax.set_ylim(0, df_country.cases.iloc[-1] * 15)\n",
    "    ax.set_title(country)\n",
    "    \n",
    "axs[0, 0].legend(['data', 'model prediction'])\n",
    "[ax.set(xlabel='Days since 100 cases') for ax in axs[-1, :]]\n",
    "[ax.set(ylabel='Confirmed cases') for ax in axs[:, 0]]\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted Cases By Country - Log Scale\n",
    "\n",
    "Y axis is on a log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#hide_input\n",
    "fig, axs = plt.subplots(nrows=n_countries // 3, ncols=3, figsize=(15, 30), sharex=True, sharey=True)\n",
    "\n",
    "for ax, country in zip(axs.flatten(), countries):\n",
    "    df_country = df_sign.loc[lambda x: x.country == country]\n",
    "    ax.plot(df_country.days_since_100, df_country.cases, color='r')\n",
    "    ax.plot(np.arange(0, post_pred[country].shape[1]), post_pred[country].T, alpha=.05, color='.5')\n",
    "    ax.plot(df_country.days_since_100, df_country.cases, color='r')\n",
    "    ax.set_yscale('log')\n",
    "    ax.get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "    ax.set_ylim(100, 1e5);\n",
    "    ax.set_title(country)\n",
    "    \n",
    "axs[0, 0].legend(['data', 'model prediction'])\n",
    "[ax.set(xlabel='Days since 100 cases') for ax in axs[-1, :]]\n",
    "[ax.set(ylabel='Confirmed cases') for ax in axs[:, 0]]\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Diagnostics - Trace Plots\n",
    "\n",
    "These are diagnostics for the model.  You can safely ignore this if not familiar with [MCMC](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "az.plot_trace(trace, compact=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About This Analysis\n",
    "\n",
    "This analysis was done by [Thomas Wiecki](https://twitter.com/twiecki)[^1]\n",
    "\n",
    "The model that we are building assumes exponential growth. This is definitely wrong because growth would just continue uninterrupted into the future. However, in the early phase of an epidemic it's a reasonable assumption.\n",
    "\n",
    "We assume a [negative binomial](https://docs.pymc.io/api/distributions/discrete.html#pymc3.distributions.discrete.NegativeBinomial) likelihood as we are dealing with count data. A Poisson could also be used but the negative binomial allows us to also model the variance separately to give more flexibility.\n",
    "\n",
    "The model is also hierarchical, pooling information from individual countries.\n",
    "\n",
    "\n",
    "[^1]:  This notebook gets up-to-date data from the [\"2019 Novel Coronavirus COVID-19 (2019-nCoV) Data Repository by Johns Hopkins CSSE\"](https://systems.jhu.edu/research/public-health/ncov/) [GitHub repository](https://github.com/CSSEGISandData/COVID-19). This code is provided under the [BSD-3 License](https://github.com/twiecki/covid19/blob/master/LICENSE). Link to [original notebook](https://github.com/twiecki/covid19/blob/master/covid19_growth_bayes.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
